# -*- coding: utf-8 -*-
"""tweets.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I_s6r7M-Y6EMg60VB4gGL6uqfY0iiqOb
"""

not_accepted =[')','(','#','-','the','.','*','?',',','a','in','!',':','/','http','www','com','\'',';','%','=','to','of','or','+','us','for','if','your','it','was','at','i','I', 'a','about','above','after','again','against','all','am','an','and','any','are','aren\'t','as','at','be','because','been','before','being','below','between','both','but','by','can\'t','cannot','could','couldn\'t','did','didn\'t','do','does','doesn\'t','doing','don\'t','down','during','each','few','for','from','further','had','hadn\'t','has','hasn\'t','have','haven\'t','having','he','he\'d','he\'ll','he\'s','her','here','here\'s','hers','herself','him','himself','his','how','how\'s','i','i\'d','i\'ll','i\'m','i\'ve','if','in','into','is','isn\'t','it','it\'s','its','itself','let\'s','me','more','most','mustn\'t','my','myself','no','nor','not','of','off','on','once','only','or','other','ought','our','ours	ourselves','out','over','own','same','shan\'t','she','she\'d','she\'ll','she\'s','should','shouldn\'t','so','some','such','than','that','that\'s','the','their','theirs','them','themselves','then','there','there\'s','these','they','they\'d','they\'ll','they\'re','they\'ve','this','those','through','to','too','under','until','up','very','was','wasn\'t','we','we\'d','we\'ll','we\'re','we\'ve','were','weren\'t','what','what\'s','when','when\'s','where','where\'s','which','while','who','who\'s','whom','why','why\'s','with','won\'t','would','wouldn\'t','you','you\'d','you\'ll','you\'re','you\'ve','your','yours','yourself','yourselves']

!pip install oauth2

import nltk
nltk.download('stopwords')

from nltk.stem.porter import *
from nltk.corpus import stopwords 
from nltk.stem.snowball import SnowballStemmer
handle_plural = PorterStemmer()
handle_adverbs=SnowballStemmer("english")
stop_words = set(stopwords.words('english')) 
def evaluateText(text):
    resulttext = ""
    textArray = text.split()
    for word in textArray:
        if word not in not_accepted and word not in stop_words:
            if(word.find("https") == -1):
                #word = handle_plural.stem(word)
                #word = handle_adverbs.stem(word)
                resulttext += word+" "
    return resulttext

def arrangeHashtags(hashtag):
    hashtags = ""
    for hash in hashtag:
        hashtags += hash['text'] + " "
    return hashtags

import oauth2 as oauth
import json
import  matplotlib as plt
from tweepy.streaming import StreamListener
from tweepy import Stream
from tweepy import API
from tweepy import Cursor
from tweepy import OAuthHandler
from tweepy import cursor
import numpy as np
import pandas as pd
import csv

icounter = 0

with open('config1.json') as file:
    tokens = json.loads(file.read())

consumer = oauth.Consumer(key= tokens['CONSUMER_KEY'], secret=tokens['CONSUMER_SECRET'])
token = oauth.Token(key= tokens['ACCESS_TOKEN'], secret= tokens['ACCESS_SECRET'])
client = oauth.Client(consumer,token)



FOLLOWRS_URL = 'https://api.twitter.com/1.1/followers/list.json'


#url = FOLLOWRS_URL+'?screen_name='+screen_name

#header, response = client.request(url,method='GET')

#print('status:',header['status'])
#return 200 means successful to connect twitter api

class twitter_data():
    def __init__(self):
        self.auth = TwitterAuthenticate().authenticate_twitter()
        self.twitter_client = API(self.auth)

    def get_tweets(self):
      self.auth = TwitterAuthenticate().authenticate_twitter()
      api = API(self.auth)
      '''for tweet in Cursor(api.user_timeline, screen_name="@elonmusk",count=100).items():
        tweet.text = evaluateText(tweet.text)
        tweet.entities['hashtags'] = arrangeHashtags(tweet.entities['hashtags'])
        print(tweet.created_at, tweet.id ,tweet.user.screen_name, tweet.text,tweet.favorite_count,tweet.retweet_count, tweet.user.location, tweet.entities['hashtags'])
        with open("tweetstill27sept.csv",'a+',encoding='utf-8') as file:
          f2 = csv.writer(file)
          
          f2.writerow([tweet.id, tweet.created_at, tweet.user.screen_name ,tweet.text.encode('utf-8'),tweet.favorite_count,tweet.retweet_count, tweet.user.location, tweet.entities['hashtags']])'''

      for tweet in Cursor(api.search, q="#tesla since:2020-12-09",count=100, lang="en", geocode= '39.8098600,-98.5551830,1500km').items():
        tweet.text = evaluateText(tweet.text)
        tweet.entities['hashtags'] = arrangeHashtags(tweet.entities['hashtags'])
        print(tweet.created_at, tweet.id ,tweet.user.screen_name, tweet.text,tweet.favorite_count,tweet.retweet_count, tweet.user.location, tweet.entities['hashtags'])
        with open("twitter.csv",'a+',encoding='utf-8') as file:
          f2 = csv.writer(file)
          f2.writerow([tweet.id, tweet.created_at, tweet.user.screen_name ,tweet.text.encode('utf-8'),tweet.favorite_count,tweet.retweet_count, tweet.user.location, tweet.entities['hashtags']])

class TwitterAuthenticate():
    def authenticate_twitter(self):
        auth = OAuthHandler(consumer_key=tokens['CONSUMER_KEY'], consumer_secret=tokens['CONSUMER_SECRET'])
        auth.set_access_token(key=tokens['ACCESS_TOKEN'], secret=tokens['ACCESS_SECRET'])
        return auth

if __name__ == "__main__":
    icounter = 0
    twitter_client = twitter_data()
    api = twitter_client.get_tweets()



