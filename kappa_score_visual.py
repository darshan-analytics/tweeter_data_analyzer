# -*- coding: utf-8 -*-
"""kappa_score_visual.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w7OuF2momnRF-00yU60c5oo71Yg-JWjd
"""

import pandas as pd
import numpy as np

df = pd.read_csv('Vader_labled_data_first100.csv')

df

df['Aditya_Sentiment'].value_counts()

df['Sahil_Sentiment'].value_counts()

df['sentiment'].value_counts()

df['Darshan_Sentiment'].value_counts()



df['sent_score'] = df['sentiment'].replace({'neutral':1,'positive':2,'negative':3})

df['adi_sent_score'] =  df['Aditya_Sentiment'].replace({'neutral':1,'positive':2,'negative':3})

df['darsh_sent_score'] = df['Darshan_Sentiment'].replace({'neutral':1,'positive':2,'negative':3})

df['sahi_sent_score'] = df['Sahil_Sentiment'].replace({'neutral':1,'positive':2,'negative':3})

to_cal = df[['sent_score','adi_sent_score','darsh_sent_score','sahi_sent_score']]

to_cal['neutral'] = (to_cal[['sent_score','adi_sent_score','darsh_sent_score','sahi_sent_score']] == 1).sum(axis = 1)

to_cal['positive'] = (to_cal[['sent_score','adi_sent_score','darsh_sent_score','sahi_sent_score']] == 2).sum(axis = 1)
to_cal['negative'] = (to_cal[['sent_score','adi_sent_score','darsh_sent_score','sahi_sent_score']] == 3).sum(axis = 1)

to_cal

to_fleiss = to_cal[['neutral','positive','negative']]
to_fleiss.loc['total'] = to_fleiss.sum(axis= 0)

to_fleiss

sum = to_fleiss.loc['total'].sum()

number_of_raters = 4

to_fleiss['Pi'] = (to_fleiss['negative'].pow(2) + to_fleiss['neutral'].pow(2) + to_fleiss['positive'].pow(2) - number_of_raters)/ (number_of_raters * (number_of_raters -1))

to_fleiss.loc['Pj'] = to_fleiss.loc['total'] / (number_of_raters *100)

to_fleiss

total = to_fleiss['Pi'].iloc[:100].sum()
total

P = total / 100

Pe = to_fleiss['negative'].loc['Pj'] **2 + to_fleiss['neutral'].loc['Pj'] **2 + to_fleiss['positive'].loc['Pj'] **2
Pe

kappa_score = (P - Pe)/ (1 - Pe)
kappa_score

"""
kappa 	Interpretation
< 0	Poor agreement
0.01 – 0.20	Slight agreement
0.21 – 0.40	Fair agreement
0.41 – 0.60	Moderate agreement
0.61 – 0.80	Substantial agreement
0.81 – 1.00	Almost perfect agreement
"""

only_raters = df[['adi_sent_score','darsh_sent_score','sahi_sent_score']]
only_raters['neutral'] = (only_raters[['adi_sent_score','darsh_sent_score','sahi_sent_score']] == 1).sum(axis = 1)
only_raters['positive'] = (only_raters[['adi_sent_score','darsh_sent_score','sahi_sent_score']] == 2).sum(axis = 1)
only_raters['negative'] = (only_raters[['adi_sent_score','darsh_sent_score','sahi_sent_score']] == 3).sum(axis = 1)
to_fleiss_rater = only_raters[['neutral','positive','negative']]
to_fleiss_rater.loc['total'] = to_fleiss_rater.sum(axis= 0)
sum_rater = to_fleiss_rater.loc['total'].sum()
number_of_raters = 3
to_fleiss_rater['Pi'] = (to_fleiss_rater['negative'].pow(2) + to_fleiss_rater['neutral'].pow(2) + to_fleiss_rater['positive'].pow(2) - number_of_raters)/ (number_of_raters * (number_of_raters -1))
to_fleiss_rater.loc['Pj'] = to_fleiss_rater.loc['total'] / (number_of_raters *100)
total_rater = to_fleiss_rater['Pi'].iloc[:100].sum()
P_rater = total_rater / 100
Pe_rater = to_fleiss_rater['negative'].loc['Pj'] **2 + to_fleiss_rater['neutral'].loc['Pj'] **2 + to_fleiss_rater['positive'].loc['Pj'] **2
kappa_score_rater = (P_rater - Pe_rater)/ (1 - Pe_rater)
kappa_score_rater

to_fleiss['Max'] = to_fleiss.idxmax(axis=1)
to_fleiss

df['Max'] = to_fleiss['Max']

print(metrics.confusion_matrix(df['Max'], df['Aditya_Sentiment'], labels=["neutral", "positive", "negative"]))
print(metrics.classification_report(df['Max'], df['Aditya_Sentiment'], labels=["neutral", 
"positive","negative"]))

print(metrics.confusion_matrix(df['Max'], df['Darshan_Sentiment'], labels=["neutral", "positive", "negative"]))
print(metrics.classification_report(df['Max'], df['Darshan_Sentiment'], labels=["neutral", 
"positive","negative"]))

print(metrics.confusion_matrix(df['Max'], df['Sahil_Sentiment'], labels=["neutral", "positive", "negative"]))
print(metrics.classification_report(df['Max'], df['Sahil_Sentiment'], labels=["neutral", 
"positive","negative"]))

print(metrics.confusion_matrix(df['Max'], df['sentiment'], labels=["neutral", "positive", "negative"]))
print(metrics.classification_report(df['Max'], df['sentiment'], labels=["neutral", 
"positive","negative"]))

"""###FOR READER ONLY"""

to_fleiss_rater['Max_reader'] = to_fleiss_rater.idxmax(axis=1)

df['Max_rater'] = to_fleiss_rater['Max_reader']

print(metrics.confusion_matrix(df['Max_rater'], df['Aditya_Sentiment'], labels=["neutral", "positive", "negative"]))
print(metrics.classification_report(df['Max_rater'], df['Aditya_Sentiment'], labels=["neutral", 
"positive","negative"]))

print(metrics.confusion_matrix(df['Max_rater'], df['Darshan_Sentiment'], labels=["neutral", "positive", "negative"]))
print(metrics.classification_report(df['Max_rater'], df['Darshan_Sentiment'], labels=["neutral", 
"positive","negative"]))

print(metrics.confusion_matrix(df['Max_rater'], df['Sahil_Sentiment'], labels=["neutral", "positive", "negative"]))
print(metrics.classification_report(df['Max_rater'], df['Sahil_Sentiment'], labels=["neutral", 
"positive","negative"]))

print(metrics.confusion_matrix(df['Max_rater'], df['sentiment'], labels=["neutral", "positive", "negative"]))
print(metrics.classification_report(df['Max_rater'], df['sentiment'], labels=["neutral", 
"positive","negative"]))

from sklearn import metrics

print(metrics.confusion_matrix(to_fleiss[''], y_pred, labels=["a", "b", "c"]))
# Printing the precision and recall, among other metrics
print(metrics.classification_report(y_act, y_pred, labels=["a", 
"b","c"]))

df_visual = pd.read_csv('Vader_labled_data.csv')

df_visual['Date'] = pd.to_datetime(df_visual['created_at']).dt.date
df_visual['counter'] = 1
date_time = df_visual.groupby('Date')['counter'].sum().reset_index()
plt.figure(figsize=(10,6))
plt.hist(date_time['Date'], bins =10, density=True, cumulative=True, histtype='stepfilled', alpha=0.4)
plt.xticks(rotation=90)
plt.show()

date_time

from matplotlib.dates import date2num
from matplotlib.dates import num2date
import matplotlib.pyplot as plt

counts, bin_edges = np.histogram(date2num(date_time['Date']), bins=10,  density = False)
x_t = date2num(date_time['Date'])
print("Prrinting the counts for histogram\n",counts)
pdf = (counts) / (counts.sum())
print("Sum of count is\n",counts.sum())

print("Printing Edges of bins \n",bin_edges)
plt.figure()
cdf = np.cumsum(pdf)
print("CDF Is as followes\n",cdf)
plt.gca().legend(('Cdf'))
plt.title('CDF For Date')
plt.xlabel("Date into num")
plt.ylabel("Percentage")
plt.plot(bin_edges[1:],cdf)
plt.xticks(rotation=90)
labels = num2date(bin_edges,tz=None)
print(labels)
plt.xticks(labels)
plt.show()

desired_width=320

pd.set_option('display.width', desired_width)
pd.set_option('max_colwidth',400)
pd.describe_option('max_colwidth')
pd.set_option('max_rows',9999)


pd.set_option('display.max_columns',20)

df_sent = df_visual.groupby(['sentiment','Date'])['counter'].sum().reset_index()
df_sent

p1 = df_sent[:73]
p2 = df_sent[73:148]
p3 = df_sent[148:]

plt.figure(figsize=(12,8))
def norm(data):
  return (data)/(max(data)-min(data))
plt.plot(p1['Date'],norm(p1['counter']), marker='o',label='negative')
plt.plot(p2['Date'],norm(p2['counter']), marker='o',label='neutral')
plt.plot(p3['Date'],norm(p3['counter']), marker='o',label='positive')
plt.legend()
plt.show()

plt.figure(figsize=(12,8))
def norm(data):
  return (data)/(max(data)-min(data))
plt.plot(p1['Date'],(p1['counter']), marker='o',label='negative')
plt.plot(p2['Date'],(p2['counter']), marker='o',label='neutral')
plt.plot(p3['Date'],(p3['counter']), marker='o',label='positive')
plt.legend()
plt.show()

df_highest = df_visual

df_highest = df_highest.dropna(subset=['hashtags'])

df_pos = df_highest.loc[df_highest['sentiment'] == 'positive']

df_neg = df_highest.loc[df_highest['sentiment']=='negative']

df_neu = df_highest.loc[df_highest['sentiment']=='neutral']

df_pos = df_pos['hashtags'].str.split(' ')

df_neg = df_neg['hashtags'].str.split(' ')

positive = []

for i in df_pos:
  positive.append(i)

final_pos = []

for i in positive:
  for j in i:
    final_pos.append(j)

final_pos = list(filter(lambda a: a!= '', final_pos))

final_pos

dictionary_for_pos = {}

for i in final_pos:
  if i in dictionary_for_pos:
    dictionary_for_pos[i] += 1
  else:
    dictionary_for_pos[i] = 1

dictionary_for_pos

final = sorted(dictionary_for_pos.items(), key=lambda x:x[1], reverse=True)
final

negative = []



for i in df_neg:
  negative.append(i)

negative

final_neg = []

for i in negative:
  for j in i:
    final_neg.append(j)

final_neg = list(filter(lambda a: a!= '', final_neg))

final_neg

dictionary_for_neg = {}

for i in final_neg:
  if i in dictionary_for_neg:
    dictionary_for_neg[i] += 1
  else:
    dictionary_for_neg[i] = 1

final_neg = sorted(dictionary_for_neg.items(), key=lambda x:x[1], reverse=True)
final_neg

list_of_pos = []
list_of_neg = []

for i in range(0,9):
  list_of_pos.append(final[i])

for i in range(0,9):
  list_of_neg.append(final_neg[i])

hashtag_pos =  [i[0] for i in list_of_pos]

hashtag_pos

hashtag_pos_counts =  [i[1] for i in list_of_pos]

hashtag_neg = [i[0] for i in list_of_neg]
hashtag_neg_counts =  [i[1] for i in list_of_neg]

plt.figure(figsize=(10,10))
plt.bar(hashtag_pos,hashtag_pos_counts)
plt.show()

plt.figure(figsize=(10,10))
plt.bar(hashtag_neg,hashtag_neg_counts)
plt.show()













